#! /usr/bin/python3
import os
import array
import math
import pickle
import joblib
import sys
import argparse
import hashlib
import re

def get_entropy(data):
    if len(data) == 0:
	    return(0.0)
    occurences = array.array('L', [0]*256)
    for x in data:
  	    occurences[x if isinstance(x, int) else ord(x)] += 1

    entropy = 0
    for x in occurences:
        if x:
            p_x = float(x) / len(data)
            entropy -= p_x*math.log(p_x, 2)

            return entropy


def get_average_name_length(data):
    '''Takes in a python .py file as a string in data. Picks out all 
    of the function, variable and class names and stores them in a 
    seperate string to make an average length calculation.
        data: input .py string information.
        variables_list: stores the list of the regex grab of all 
        of the variable, function and class names. 
        string: stores the sorted string from the list before 
        processing.
    '''
    if len(data) == 0:
	    return(0.0)
    else:
        data = str(data)
    ## isolate every variable, class, and function name 
    variables_list = re.findall(
        r'(\w+)(?=\s=)|(\w+)(?==)|(?<=def\s)(\w+)|(?<=class\s)(\w+)'
        , data)

    ## trim off the excess empty strings that regex generates
    string = ''
    if not variables_list:
        return(0.0)
    else:
        for i in variables_list:
            string += "".join(map(str, i)) + " "
    if string:
        string_list  = string.split(' ')
        temp = 0
        for i in string_list:
            temp += len(i)
        average = temp /(len(string_list) + 1)
        return(average)


def get_variable_name_entropy(data):
    '''Takes in a python .py file as a string in data. Picks out all 
    of the function, variable and class names and stores them in a 
    seperate string to make an entropy calculation. 
        data: input .py string information.
        variables_list: stores the list of the regex grab of all 
        of the variable, function and class names. 
        string: stores the sorted string from the list before 
        processing.
    '''
    if len(data) == 0:
	    return(0.0)
    else:
        data = str(data)
    ## isolate every variable, class, and function name 
    variables_list = re.findall(
        r'(\w+)(?=\s=)|(\w+)(?==)|(?<=def\s)(\w+)|(?<=class\s)(\w+)'
        , data)
    # print(variables_list)
    
    ## trim off the excess empty strings that regex generates
    string = ''
    if not variables_list:
        return(0.0)
    else:
        for i in variables_list:
            # print("".join(map(str, i)))
            string += "".join(map(str, i)) + " "
    if string:
        # print(string)
        return(get_entropy(string) )


def conatins_IP_addresses(data):
    '''Takes in a python .py file as a string in data. Picks out all 
    of the ip addresses and returns true if the data contains ip 
    addresses. 
        data: input .py string information.
        variables_list: stores the list of the regex grab of all 
        the ip addresses. 
        string: stores the cherry picked string from the list before 
        processing.
    '''
    if len(data) == 0:
	    return(0.0)
    else:
        data = str(data)
    ## isolate every variable, class, and function name 
    variables_list = re.findall(
        r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}"
        , data)
    string = ''
    if not variables_list:
        pass
    else:
        for i in variables_list:
            # print("".join(map(str, i)))
            string += "".join(map(str, i)) + " "
    if string:
        return(1)  #True
    else:
        return(0) #False


def extract_infos(bytestring):
    res = {}
    data = bytestring.encode()
    m = hashlib.md5(bytestring.encode('ascii')).hexdigest()    # hash that badboy!!
    stringData = bytestring.encode("ascii")
    # print(digest)         ## test prints
    # res["Name"]=file
    res["md5"]=m
    res["entropy"]=get_entropy(data)
    res["imports"]=data.count(b"import")
    # res["Average variable name length"]=
    res["good"]=data.count(b"good")
    res["bad"]=data.count(b"bad")
    res["line count"]=stringData.count(b"\n")
    res["mean name length"]=get_average_name_length(stringData)
    res["variable entropy"]=get_variable_name_entropy(stringData)
    res["contains ip address"]=conatins_IP_addresses(stringData)
    # print(res)              ## test prints
    return(res)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Detect malicious files')
    parser.add_argument('BYTESTREAM', help='Stream of string to be tested')
    args = parser.parse_args()
    print(args.BYTESTREAM)
    # Load classifier
    clf = joblib.load(os.path.join(
        os.path.dirname(os.path.realpath(__file__)),
        'classifier/classifier_ab.pkl'
    ))
    features = pickle.loads(open(os.path.join(
        os.path.dirname(os.path.realpath(__file__)),
        'classifier/features_ab.pkl'),
        'rb').read()
    )

    data = extract_infos(args.BYTESTREAM)

    # print(f"this is the data: {data}")

    string_features = list(map(lambda x:data[x], features))

    res= clf.predict([string_features])[0]
    print('The String is %s' % (
        ['malicious', 'legitimate'][res])
    )

    # exec(args.BYTESTREAM.encode("ascii"))